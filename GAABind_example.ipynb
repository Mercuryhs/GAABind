{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAABind Tutorial\n",
    "This notebook is an example of how to use GAABind to predict the ligand binding conformation and binding affinity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the input dataset\n",
    "First, you need to prepare the input dataset using the following format, :\n",
    "```bash\n",
    "1e66/\n",
    "├── ligand.mol2\n",
    "├── ligand.sdf\n",
    "├── pocket.txt\n",
    "└── receptor.pdb\n",
    "```\n",
    "The ligand file can be in .sdf, .mol2, or .mol format, or you can provide the ligand's SMILES representation in a .txt file. The pocket.txt contains the residues of binding pockets, each residue is named by the chain, residue number, and three-letter abbreviation as follows:\n",
    "```bash\n",
    "A_81_TRP\n",
    "A_77_GLY\n",
    "A_439_TYR\n",
    "A_331_TYR\n",
    "A_120_GLY\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input dataset path\n",
    "input_path = './example_data/1e66'   #replace the path by your own dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dataset path:  ./example_data/1e66/ligand.sdf ./example_data/1e66/receptor.pdb ./example_data/1e66/pocket.txt\n",
      "using the following reisudes as target pocket:  A_81_TRP,A_77_GLY,A_439_TYR,A_331_TYR,A_120_GLY,A_437_HIS,A_330_LEU,A_429_TRP,A_198_ALA,A_75_PHE,A_287_PHE,A_115_GLY,A_438_GLY,A_197_SER,A_118_TYR,A_328_PHE,A_72_PHE,A_285_PHE,A_441_ILE,A_124_LEU,A_114_GLY,A_117_PHE,A_327_PHE,A_69_ASP,A_82_ASN,A_119_SER,A_433_MET,A_436_ILE,A_78_SER,A_196_GLU,A_116_GLY,A_127_TYR\n"
     ]
    }
   ],
   "source": [
    "# find the coresponding path for the input ligand, protein and pocket information.\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "name = os.path.basename(input_path)\n",
    "mol_file = glob(f'{input_path}/ligand.*')[0]\n",
    "pro_file = f'{input_path}/receptor.pdb'\n",
    "pocket_file = f'{input_path}/pocket.txt'\n",
    "poc_res = open(pocket_file).read().splitlines()\n",
    "print('using dataset path: ', mol_file, pro_file, pocket_file)\n",
    "print('using the following reisudes as target pocket: ', ','.join(poc_res))\n",
    "\n",
    "output_dir = './example_output' #replace the save path by your own\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries for data preprocess\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import argparse\n",
    "from glob import glob\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from data.feature_utils import get_ligand_info, get_protein_info, get_chem_feats, read_mol, get_coords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating the dataset features for model input\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "output_path = os.path.join(output_dir, f'{name}.pkl')\n",
    "new_data = {}\n",
    "input_mol = read_mol(mol_file)\n",
    "try:\n",
    "    mol, smiles, coordinate_list = get_coords(input_mol)\n",
    "except:\n",
    "    print(f'generate input ligand coords failed for {name}')\n",
    "\n",
    "lig_atoms, lig_atom_feats, lig_edges, lig_bonds = get_ligand_info(mol)\n",
    "poc_pos, poc_atoms, poc_atom_feats, poc_edges, poc_bonds = get_protein_info(pro_file, poc_res)\n",
    "\n",
    "new_data.update({'atoms': lig_atoms, 'coordinates': coordinate_list, 'pocket_atoms': poc_atoms,\n",
    "                'pocket_coordinates': poc_pos, 'smi': smiles, 'pocket': name,'lig_feats': lig_atom_feats,\n",
    "                'lig_bonds': lig_edges, 'lig_bonds_feats': lig_bonds, 'poc_feats': poc_atom_feats, \n",
    "                'poc_bonds': poc_edges, 'poc_bonds_feats': poc_bonds, 'mol': mol})\n",
    "\n",
    "new_data = get_chem_feats(new_data)\n",
    "\n",
    "f_out = open(output_path, 'wb')\n",
    "pickle.dump(new_data, f_out)\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Binding conformation prediction using GAABind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required libraries for prediction\n",
    "import torch\n",
    "import pandas as pd\n",
    "from utils import set_global_seed\n",
    "from data.graph_dataset import DockingTestDataset\n",
    "from data.collator import collator_test_3d\n",
    "from option import set_args\n",
    "from models.DockingPoseModel import DockingPoseModel\n",
    "from docking.docking_utils import (\n",
    "    docking_data_pre,\n",
    "    ensemble_iterations,\n",
    ")\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model and model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "parser = set_args()\n",
    "args = parser.parse_args(args=[])\n",
    "set_global_seed(args.seed)\n",
    "ckpt_path = './saved_model/best_epoch.pt'\n",
    "state_dict = torch.load(ckpt_path, map_location='cpu')\n",
    "new_state_dict = dict()\n",
    "for key in state_dict.keys():\n",
    "    layer_name = key[7:]\n",
    "    new_state_dict[layer_name] = state_dict[key]\n",
    "\n",
    "model = DockingPoseModel(args).to(device)\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset and run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.31it/s]\n"
     ]
    }
   ],
   "source": [
    "inference_save_path = os.path.join(output_dir, 'example_inference.pkl')   #define the save path of inference\n",
    "test_dataset = DockingTestDataset(output_dir, args.conf_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=False, collate_fn=collator_test_3d)\n",
    "\n",
    "outputs = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        for dicts in batch[:2]:\n",
    "            for key in dicts.keys():\n",
    "                dicts[key] = dicts[key].to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(batch)\n",
    "\n",
    "        mol_token_atoms = batch[0]['x'][:,:,0]\n",
    "        poc_token_atoms = batch[1]['x'][:,:,0]\n",
    "        poc_coords = batch[1]['pos']\n",
    "\n",
    "        logging_output = {}\n",
    "\n",
    "        logging_output[\"smi_name\"] = batch[2]['smi_list']\n",
    "        logging_output[\"pocket_name\"] = batch[2]['pocket_list']\n",
    "        logging_output['mol'] = batch[2]['mol']\n",
    "        logging_output[\"cross_distance_predict\"] = pred[0].data.detach().cpu().permute(0, 2, 1)\n",
    "        logging_output[\"holo_distance_predict\"] = pred[1].data.detach().cpu()\n",
    "        logging_output[\"atoms\"] = mol_token_atoms.data.detach().cpu()\n",
    "        logging_output[\"pocket_atoms\"] = poc_token_atoms.data.detach().cpu()\n",
    "        logging_output[\"holo_center_coordinates\"] = batch[2]['holo_center_list']\n",
    "        logging_output[\"pocket_coordinates\"] = poc_coords.data.detach().cpu()\n",
    "        logging_output['pred_affinity'] = pred[-1].data.detach().cpu()\n",
    "        outputs.append(logging_output)\n",
    "\n",
    "    pickle.dump(outputs, open(inference_save_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ligand binding pose by using the inference result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction fininshed !!!!! You can find the result in the ./example_output/1e66 directory\n"
     ]
    }
   ],
   "source": [
    "mol_list, smi_list, pocket_list, pocket_coords_list, distance_predict_list, holo_distance_predict_list,\\\n",
    "        holo_center_coords_list, pred_affi_list = docking_data_pre(inference_save_path)\n",
    "iterations = ensemble_iterations(mol_list, smi_list, pocket_list, pocket_coords_list, distance_predict_list,\\\n",
    "                                     holo_distance_predict_list, holo_center_coords_list, pred_affi_list)\n",
    "\n",
    "cache_dir = os.path.join(output_dir, \"cache\")\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "cache_file = os.path.join(cache_dir, f'{name}.pkl')\n",
    "\n",
    "pd.to_pickle(next(iterations), cache_file)\n",
    "\n",
    "output_ligand_path = os.path.join(output_dir, name)\n",
    "cmd = \"python docking/coordinate_model.py --input {}  --output-path {}\".format(cache_file, output_ligand_path)\n",
    "os.system(cmd)\n",
    "print(f'Prediction fininshed !!!!! You can find the result in the {output_ligand_path} directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c836e6f3b794a16af7f5d81bbe56919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nglview \n",
    "predicted_file = os.path.join(output_ligand_path, 'ligand.sdf')\n",
    "view = nglview.show_file(nglview.FileStructure(pro_file), default=False)\n",
    "view.add_representation('cartoon', selection='protein', color='white')\n",
    "\n",
    "pred_lig = view.add_component(nglview.FileStructure(predicted_file), default=False)\n",
    "pred_lig.add_ball_and_stick(color='red')\n",
    "\n",
    "native = view.add_component(nglview.FileStructure(mol_file), default=False)\n",
    "native.add_ball_and_stick(color='yellow', selection='not hydrogen')\n",
    "\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mercury",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
